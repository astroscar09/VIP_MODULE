{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Handeling in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening and Writing files is an important skill in any context. It saves you work and allows for debugging in your code if you can save output out to a file. This skill is necessary both in research but also for more practical purposes such as working in any tech job as they are always collecting data and storing that data into a file for later analysis. This jupyter notebook will help you get the skills and knowledge on how to properly import data from files into python. \n",
    "\n",
    "## Note:\n",
    "This notebook will $\\textbf{not}$ cover data analysis techniques I will save that for another notebook, this will only cover how to import data from a file into your python notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Handeling:\n",
    "\n",
    "As with everything there is a set of criteria that need to be meet when you star working with files and how to properly work with them. I have listed a few of those coding practices here.\n",
    "\n",
    "1. Need the filepath to the file we are interested in importing, if we do not have this we cannot open the file\n",
    "2. Need to have something that can read it and provide you with the content of the file, these are through pythons built in functions or functions from packages\n",
    "3. We need a way to store the data, this can be storing the data into arrays or a list\n",
    "4. Once the data is stored you do not need the file anymore so we need to close it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Python's built in Functions\n",
    "\n",
    "If you know the file's location then we can get to work on trying to read the contents of it into python. As with other files one must know some basics of the file before working with python. For example, are there column names, how is the data separated int he file (ie. spaces or commas, something else) and what kinds of data is stroed here (numerical or characters, such as names and addresses). Once you know what is in the file we can load it into python by using the $\\textbf{open}$ function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using open() to read a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is code that reads in the file.\n",
    "#Comments:\n",
    "#1. make sure to put the filename in quotes and what you want to do with that file\n",
    "#in this case we want to read it and so that is what the 'r' is telling python\n",
    "#one assumption this makes is that this assumes the file is ALREADY in the CURRENT directory\n",
    "file = open('Filename', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For files that are not in the current directory we need to specify the full file path\n",
    "file = open('/path/to/the/file/Filename, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python File Hack\n",
    "\n",
    "If you do not know the file contents before hand, Python has a function called read that will be able to show you the file contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to see the contents of the ENTIRE file we will use the read option\n",
    "print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to read only a specific line in the file you can use pythons function called readline which displays the line you are interested. By default it shows it line by line but you can put in any number and it will display that line of the file, but recall pythons zero index so line 1 is index 0, line 2 is index 1 and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to see only one line in the file we will use the readline option\n",
    "print(file.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you open the file you can actually loop over the contents of each line using a for loop. Which is what we will do to get the data we are interested in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can also loop through the file line by line using the following:\n",
    "for line in file:\n",
    "  print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the above python hacks in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we know how to go through a file line by line we need a way to store the contents of it\n",
    "#This requires you to know beforehand the layout of the file\n",
    "#(ie how many columns, what those columns means, what seperates the values: white space, commas etc.)\n",
    "#take a quick look into the file Fileio_Ex1.txt file\n",
    "\n",
    "#this opens the file and stores the contents into the variable called file\n",
    "file = open('Fileio_Ex1.txt', 'r')\n",
    "\n",
    "#maing lists that will hold the information for column1 and column2\n",
    "column1 = []\n",
    "column2 = []\n",
    "\n",
    "#this for loop will go through line by line of the file\n",
    "for line in file:\n",
    "    \n",
    "    #for each line in the file we split the line according to spaces and store this in separate lists\n",
    "    separated_line = line.split(' ')\n",
    "    \n",
    "    #here we append the numbers noting that 0 is column-1 and 1 is column-2\n",
    "    column1.append(float(seperated_line[0]))\n",
    "    column2.append(float(seperated_line[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#closing the file and making room in memory for other tasks\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Congratulation you read in your first file :D!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A note on .split():\n",
    "\n",
    "One thing you may have noticed that we needed to do here is use a .split() function. This is something that we have not covered as of yet and I will expand upon what it does and why we needed to do this in this example. The .split() command is a really cool string method. if we have a string named string = 'To Kill a Mockingbird' and we want to break this string up so we have the individual words of the title we can use .split for this. \n",
    "\n",
    "What we do is take the variable name of the string, in this case string, and apply the .split() to it. \n",
    "\n",
    "string.split()\n",
    "\n",
    "By default it will split a string along a blank space but you can give it what you want the function to split against. Say you had a full filepath like filepath = '/Users/oac466/Desktop/VIP_Modules/Module1/file.txt' and you were only interested in the text file. You could apply split to split the string along the '/' and get the file.txt. \n",
    "\n",
    "An example of this is:\n",
    "\n",
    "filepath.split('/')\n",
    "\n",
    "Whenever you use split on a string it returns back a $\\textbf{list}$ with the entries split up according to the split criteria. In the filepath example you would get back a list like:\n",
    "\n",
    "['', 'Users', 'oac466', 'Desktop', 'VIP_Modules', 'Module1', 'file.txt']\n",
    "\n",
    "Then to get the txt file you can use indexing to get it\n",
    "\n",
    "txtfile = filepath.split('/')[-1]\n",
    "\n",
    "\n",
    "Since the file we were reading was only single spaced delimited we needed to split across a single space hence why in split we added in the .split(' ') to be explicit that we want to split across a single space. Then we get a list back for each row and then we needed to get the relevant data from the resultant list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/Users/oac466/Desktop/VIP_Modules/Module1/file.txt'\n",
    "\n",
    "print(filepath.split('/'))\n",
    "print()\n",
    "print(filepath.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets use this example to get the ID from this filepath, first we would need to split it across '_' and then\n",
    "#grab the last entry of the returned list which will be 098234.fits then split again across the '.'\n",
    "#to get the first entry of the list\n",
    "filename = 'ceers_nirspec4_098234.fits'\n",
    "\n",
    "filename.split('_')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can also split across the '.' first to get the first entry of the list which will be ceers_nirspec4_098234\n",
    "#then split across the '_' to get the last entry to get the ID\n",
    "filename.split('.')[0].split('_')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise Numero 1\n",
    "\n",
    "Use .split() to get the \"a\" in the variable booktitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booktitle = 'To Kill a Mockingbird'\n",
    "\n",
    "#code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding the above example to more complex files\n",
    "\n",
    "To make the above exmaple more robust for more advanced files we may need to change:\n",
    "\n",
    "1. The number of columns\n",
    "2. how the data are seperated, maybe instead of spaces, they are separated by using commas so instead of line.split(' ') we would need to use line.split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing a File\n",
    "\n",
    "To write a file onto your computer it is best to follow the procedure outlined below. \n",
    "\n",
    "1. Make your data easy to go through\n",
    "2. Keep track of how many columns there will be\n",
    "3. Once the max number of columns have been reached execute the new line command '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets store the following data:\n",
    "column_names = ['Hours', 'Money']\n",
    "\n",
    "\n",
    "#total hours worked. How many values are stored here?\n",
    "Hours = range(1, 11)\n",
    "\n",
    "#total money earned working that number of hours\n",
    "Money = [15 * x for x in hours] #this is called a list comprehension it is a quick way to populate a list using a\n",
    "                                #for loop inside it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: \n",
    "I would recommend testing your output by printing a few of them and seeing how the output looks like. Once the output is as you want then you can write to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: Note the difference with this one where we specified 'w' instead of 'r' as the \n",
    "#parameter. What this does is let python know that we want to write out to a file\n",
    "output_file = open('Money_Earned.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this counter will go through the data array\n",
    "counter = 0\n",
    "\n",
    "for i in range(11):\n",
    "    \n",
    "    #if it is the first thing in the loop then we will put the column names \n",
    "    #since they are on a different list\n",
    "    if i == 0:\n",
    "        \n",
    "        #Here we are testing it out so we use print and take note of the '\\n' at the end\n",
    "        #if you do not have that then it will write the following items in the same line in your output file\n",
    "        print(column_names[0] + ' ' + column_names[1] + '\\n')\n",
    "        #output_file.write(column_names[0] + ' ' + column_names[1] + '\\n')\n",
    "    else:\n",
    "        \n",
    "        #this is the code that will store number of hours worked and the money earned also take note of the '\\n'\n",
    "        #command here\n",
    "        print(str(Hours[counter]) + ' ' + str(Money[counter]) + '\\n')\n",
    "        #output_file.write(str(Hours[counter]) + ' ' + str(Money[counter]) + '\\n')\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is the code that will actually write the contents out to the file\n",
    "#After you run this one you should see a file pop up in the directory titled Money_Earned.txt\n",
    "#and if you open it up you shoud see what was printed above\n",
    "\n",
    "counter = 0\n",
    "for i in range(11):\n",
    "    \n",
    "    if i == 0:\n",
    "        #print(column_names[0] + ' ' + column_names[1] + '\\n')\n",
    "        output_file.write(column_names[0] + ' ' + column_names[1] + '\\n')\n",
    "    else:\n",
    "        #print(str(Hours[counter]) + ' ' + str(Money[counter]) + '\\n')\n",
    "        output_file.write(str(Hours[counter]) + ' ' + str(Money[counter]) + '\\n')\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After you write out to a file it is customary to close the file\n",
    "#so you do not accidentally write more data to it\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "\n",
    "1. With the open function you can read and write files using python. \n",
    "2. You can loop through each line in the file and if you know what separates the data you can use the .split() command to split the columns apart\n",
    "3. Once you split up the data then you should append the data to lists or arrays and do any data type conversions that you deem fit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File-io with Packages\n",
    "\n",
    "1. Numpy \n",
    "    \n",
    " Reading Files   \n",
    " - loadtxt\n",
    " - genfromtxt\n",
    " \n",
    " Writing Files\n",
    " \n",
    " - savetxt\n",
    " - savez\n",
    " - save\n",
    " \n",
    " \n",
    "2. Pandas\n",
    "\n",
    " Reading Files\n",
    " - read_csv\n",
    " \n",
    " Writing Files\n",
    " - to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the packages to read in the files\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# np.loadtxt\n",
    "\n",
    "To use np.loadtxt all you need is the file path for the file. You input this into the function and it will read it for you. However, one assumption that loadtxt makes is that it assumes that the data in your file are all floats. \n",
    "\n",
    "This means that if you have a columns with names, for example, loadtxt will probably fail to load it into python. One thing you can do to fix this is to read in everything in the file as strings by changing the datatype that loadtxt reads it into. Then change the data types after the file has been loaded into python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since all we have are numerical data we can read it in and it gets stored as a 2D array\n",
    "data = np.loadtxt('Fileio_Ex1.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#by adding in the unpack = True argument you can split the columns up and store them to their own \n",
    "#variables as shown below column 1 is x and column 2 is y\n",
    "x, y = np.loadtxt('Fileio_Ex1.txt', unpack = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## np.genfromtxt\n",
    "\n",
    "genfromtxt works very similar to loadtxt but has other features that are not included in loadtxt such as changing delimeter types, and specifing missing values and what to assign them. It is more robust in handeling complex files and has lots of features that make it more versatile than loadtxt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the file stores them as a 2D array\n",
    "data_gen = np.genfromtxt('Fileio_Ex1.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using unpack to split the columns to their own variables\n",
    "x_gen, y_gen = np.genfromtxt('Fileio_Ex1.txt', unpack = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note on np.loadtxt vs np.genfromtxt\n",
    "\n",
    "Both are very good for opening .txt files and other files such as .dat files. However, there is a time when one is preferred over another. If you are dealing with very simple data and all the data is of the same type (ie. all numbers) then np.loadtxt would be best for that task as it is great for handeling very simple numerical files. But if you have more complex data where you have different data types in the file then loadtxt will not work. In this case genfromtxt is the way to go as it can handle more complex files. Think of loadtxt as a very specific version of genfromtxt and genfromtxt as the general function that could work for most files you have. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more complex file\n",
    "\n",
    "In the directory there are two more files each with increasing difficulty in reading in the file using loadtxt and genfromtxt. The first is an exponential decay text file, the thing that makes this a bit tricky is that it has a header on the top which is good for us but not good for loadtxt, so we need a work around for laoding this in. Let us see how we would load something like this in using loadtxt and genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_decay_array = np.loadtxt('Exponential_Decay_Exercise.txt', \n",
    "                             skiprows = 1, #we skip over the header as this would not have been read by loadtxt\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_decay_array_gen = np.genfromtxt('Exponential_Decay_Exercise.txt', \n",
    "                             skip_header = 1, #we skip over the header as this would not have been read by loadtxt\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last example is one where we have an entire column of strings. Look into the Field_Coordinates.txt file and you will see a FIELD columns which outlines which field these sources belong to. We will need to change up how we read in this file but there are work arounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1D Array\n",
    "Field = np.loadtxt('Field_Coordinates.txt', \n",
    "           usecols = (4), #only getting the numerical data\n",
    "           skiprows = 1, #skipping the header in the file\n",
    "                  dtype = str)\n",
    "\n",
    "print(Field)\n",
    "\n",
    "#2D Array\n",
    "num_data = np.loadtxt('Field_Coordinates.txt', \n",
    "           usecols = (0, 1, 2, 3), #only getting the numerical data\n",
    "           skiprows = 1, #skipping the header in the file\n",
    "           )\n",
    "\n",
    "print(num_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Field_gen = np.genfromtxt('Field_Coordinates.txt', \n",
    "           usecols = (4), #only getting the numerical data\n",
    "           skip_header = 1, #skipping the header in the file\n",
    "           dtype=str)\n",
    "\n",
    "print(Field_gen)\n",
    "num_data_gen = np.genfromtxt('Field_Coordinates.txt', \n",
    "                               usecols = (0, 1, 2, 3), #only getting the numerical data\n",
    "                               skip_header = 1, #skipping the header in the file\n",
    "                               )\n",
    "\n",
    "print(num_data_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Files with Numpy\n",
    "\n",
    "The best way for writing a txt file in python is using the np.savetxt command and the easiest way to save data is to have them all in a numpy array for more ease. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the fmt option I wrote here is optional\n",
    "#this tells np.savetxt to save the contents as a string\n",
    "#this is good when you have different data types\n",
    "np.savetxt('FileName', data, fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing Pandas to Read Files\n",
    "\n",
    "Pandas is a really cool package that allows tons of flexibility when reading many different file format such as excel, text files and even csv. We will go over how it works and how to use them to read and write out data.\n",
    "\n",
    "The great thing about pandas is that it infers the column types and the column names form the file itself. So long as there is no weird things happening in the file, pandas is a great tool to use when reading in files as lots of the guess work and hard-coding is taken care of by pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.read_csv('hipparcos_voidmain.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to see the first 5 rows we can use the .head() command\n",
    "\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Text Files\n",
    "\n",
    "By default read_csv is great at reading in csv files which uses the ',' to separate values. If you want to read text files you would need to change the separator from the ',' to a blank space and you can do that using the sep argument and setting it equal to a blank space. Let us see an example of it in use below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_Field_txt = pd.read_csv('Field_Coordinates.txt', sep = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_Field_txt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_expdecay_txt = pd.read_csv('Exponential_Decay_Exercise.txt', \n",
    "                              sep = ' ', \n",
    "                              index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_expdecay_txt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_expdecay_txt = pd.read_csv('Fileio_Ex1.txt', \n",
    "                              sep = ' ', \n",
    "                              names = ['column1', 'column2'], #I added these columns names here since this file\n",
    "                                                              #did not have them\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_expdecay_txt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Files\n",
    "\n",
    "You typically will have a Pandas DataFrame and this can be saved using the to_csv() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting a boolean mask where the field was equal to AEGIS\n",
    "aegis_mask = DF_txt.FIELD == 'AEGIS'\n",
    "\n",
    "#applying the mask on the DF\n",
    "aegis_DF = DF_txt[aegis_mask]\n",
    "\n",
    "#saving the DF as a text file named AEGIS_Galaxies.txt\n",
    "aegis_DF.to_csv('AEGIS_Galaxies.txt', sep = ' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Introduction to MCMC and emcee\n",
    "\n",
    "In this notebook we will go over what MCMC means and what exactly is it that is going on when we run an MCMC algorithm such as Metropolist-Hasting or a code like emcee. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is MCMC?\n",
    "\n",
    "Markov Chain Monte Carlo (MCMC) is a class of algorithms used to sample from a probability distribution. It is particularly useful when dealing with high-dimensional spaces where traditional sampling methods are inefficient. MCMC methods construct a Markov chain that has the desired distribution as its equilibrium distribution. By simulating the Markov chain, we can obtain samples from the target distribution. As astronomers we do a lot of work trying to estimate physical paramters on astrophysical sources such as stars, galaxies and cosmology. Most of the time the target distribution we are after is getting a handle on the parameters for a certain model and the uncertainties on those parameters. MCMC comes in handy to sample the parameter spaces for these complex models and allows us to see how constrained certain parameters are. \n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **Markov Chain**: A sequence of random variables where the distribution of each variable depends only on the state of the previous one.\n",
    "- **Monte Carlo**: Refers to the use of random sampling to estimate numerical results.\n",
    "- **Equilibrium Distribution**: The distribution to which the Markov chain converges after a large number of steps.\n",
    "\n",
    "### Common MCMC Algorithms\n",
    "\n",
    "- **Metropolis-Hastings**: A widely used MCMC algorithm that generates a sequence of samples by proposing moves to new states and accepting or rejecting them based on a certain probability.\n",
    "- **Gibbs Sampling**: A special case of the Metropolis-Hastings algorithm where each variable is sampled from its conditional distribution given the current values of the other variables.\n",
    "\n",
    "### Applications\n",
    "\n",
    "MCMC methods are used in various fields such as:\n",
    "\n",
    "- Bayesian statistics for posterior distribution sampling\n",
    "- Computational physics for simulating systems with many degrees of freedom\n",
    "- Machine learning for training models with complex likelihood functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why do we use MCMC to begin with? \n",
    "\n",
    "# Introducing Bayesian Statistics\n",
    "\n",
    "The reason why we go ahead and use MCMC to begin with is because we are using a Bayesian framework to understand the features we are studying. To start our Bayesian journey we need to go over the main equation that is driving Bayesian Statistics forward, Bayes Theorem:\n",
    "\n",
    "$P(\\theta | x) = \\frac{P(x|\\theta)P(\\theta)}{P(x)}$\n",
    "\n",
    "Let us unpack the above equation:\n",
    "\n",
    "$P(\\theta|x)$ is the quantity we are trying to find which is the probability of acquiring certain parameters $\\theta$ provided the data, $x$. In Bayesian terms this is the *Posterior* Distribution. $P(x|\\theta)P(\\theta)$ is a combination of the *likelihood* function $P(x|\\theta)$, which is the probability of acquiring the data for a set of input quantities $\\theta$ and $P(\\theta)$ is the *prior* which is the probability of getting those parameters.\n",
    "\n",
    "The denominator is the total probability of acquiring the data, a way to get this is by integrating over all possible values of $\\theta$:\n",
    "\n",
    "$P(x) = \\int P(x, \\theta) d\\theta$\n",
    "\n",
    "However, this integral is non-trivial to solve most of the time. This is reason why we use MCMC, as a way to get back the posterior distribution we are interested in. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does MCMC work?\n",
    " \n",
    "The first thing we have to do when starting MCMC is to provide an MCMC algorithm with an initial guess on the parameters we are interested in. Then you propose a move jump from the starting point to another point, these jumps can be as simple or complex as you want. Let us say for the sake of this example that you propose a jump that is a normal distribution centered at 0 and has a standard deviation of 1. So let us take our starting value as 1, the jumps we can take can be anything within the x-values as shown in the plot below:\n",
    "\n",
    "![alt text](jump_norm.png \"jumps\")\n",
    "\n",
    "We can see the normal distribution above and the x-values are the potential jumps that we can take and the probaility of jumping to those x-values are shown in the y-axis. This means that a jump value of 0 is more likely than any other jumps. \n",
    "\n",
    "So let us say that we drew a jump value of -0.5 that means that we will take the current value update it with a value of -0.5 by adding it to our current value and that will give us another value. We then see if this new value that we are at is better than the previous value we were at. So how do we quantify this as a better value?\n",
    "\n",
    "The way we do this is by comparing the likelihood of getting that parameter against the priors on that parameters to compute a likelihood and we see which parameter has a higher likelihood. We then take the ratio of the two likelihoods and then we will accept the new value if this ratio is higher than a random value drawn between 0 and 1. If it is then we accept the jump, if not we stay at the current value and do another jump to a different value. Then we repeat this process until the parameters converge. \n",
    "\n",
    "These values that jump from one value to another have a term for them called \"walkers\". Their role is to explore or walk around the parameter space to explore the values that have the highest likelihood.\n",
    "\n",
    "Things to note about the jumps to look out for:\n",
    "\n",
    "- The jump size is something that takes some fine tuning because you want the jumps to be distinct from the current value but you do not want to take too big of a jump that you miss out on values. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example with emcee: Fitting a Line\n",
    "\n",
    "We will go over implimenting MCMC using a package called emcee in the cells below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Generating the data that we are trying to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(134)\n",
    "\n",
    "# Choose the \"true\" parameters.\n",
    "m_true = -0.9594\n",
    "b_true = 4.294\n",
    "f_true = 0.534\n",
    "\n",
    "# Generate some synthetic data from the model.\n",
    "N = 50\n",
    "x = np.sort(10 * np.random.rand(N))\n",
    "yerr = 0.1 + 0.5 * np.random.rand(N)\n",
    "y = m_true * x + b_true\n",
    "y += np.abs(f_true * y) * np.random.randn(N)\n",
    "y += yerr * np.random.randn(N)\n",
    "\n",
    "plt.errorbar(x, y, yerr=yerr, fmt=\".k\", capsize=0)\n",
    "x0 = np.linspace(0, 10, 500)\n",
    "plt.plot(x0, m_true * x0 + b_true, \"k\", alpha=0.3, lw=3)\n",
    "plt.xlim(0, 10)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Generate Likelihood Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(theta, x, y, yerr):\n",
    "    m, b, log_f = theta\n",
    "    model = m * x + b\n",
    "    sigma2 = yerr**2 + model**2 * np.exp(2 * log_f)\n",
    "    return -0.5 * np.sum((y - model) ** 2 / sigma2 + np.log(sigma2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Making the Prior Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior(theta):\n",
    "    m, b, log_f = theta\n",
    "    if -5.0 < m < 0.5 and 0.0 < b < 10.0 and -10.0 < log_f < 1.0:\n",
    "        return 0.0\n",
    "    return -np.inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Merging the Likelihood and Prior into a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_probability(theta, x, y, yerr):\n",
    "    lp = log_prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_likelihood(theta, x, y, yerr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Generating Walkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emcee\n",
    "\n",
    "# Initial guess   m,   b, log(f)        #generating 32 random walkers for each of the parameters\n",
    "pos =  np.array([-0.8, 4, 0.1])+ 1e-4 * np.random.randn(32, 3)\n",
    "\n",
    "nwalkers, ndim = pos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Running Emcee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = emcee.EnsembleSampler(nwalkers, \n",
    "                                ndim, \n",
    "                                log_probability, \n",
    "                                args=(x, y, yerr)\n",
    "                                )\n",
    "\n",
    "sampler.run_mcmc(pos, 5000, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Post-Emcee Run Analysis\n",
    "\n",
    "Once emcee has finished running, we need to make sure that emcee has converged. The way to do this is by plotting \"trace\" plots which are all the values each of the walkers have explored. By the end of the run they should be moving around the final values. The walkers for your parameters should look like this towards the end of the emcee run.\n",
    "\n",
    "![alt text](converge_emcee.png \"converge_emcee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the traces of the walkers\n",
    "fig, axes = plt.subplots(3, figsize=(10, 7), sharex=True)\n",
    "samples = sampler.get_chain()\n",
    "labels = [\"m\", \"b\", \"log(f)\"]\n",
    "for i in range(ndim):\n",
    "    ax = axes[i]\n",
    "    ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
    "    ax.set_xlim(0, len(samples))\n",
    "    ax.set_ylabel(labels[i])\n",
    "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "axes[-1].set_xlabel(\"step number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "flat_samples = sampler.get_chain(discard=100, thin=15, flat=True)\n",
    "fig = corner.corner(\n",
    "    flat_samples, labels=labels, truths=[m_true, b_true, np.log(f_true)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_dictionary = {'m': flat_samples[:, 0], \n",
    "                   'b': flat_samples[:, 1], \n",
    "                   'logf': flat_samples[:, 2]}\n",
    "\n",
    "df = pd.DataFrame(data_dictionary)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('emcee_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Quantifying Parameters and Uncertainties\n",
    "\n",
    "Once we have checked that emcee has converged and the output looks good. We now have a distribution for each parameter so how do we quantify this for a paper or poster. One of the ways we can do this is by quoting the percentiles of this distribution. Specifically, the 50th percentile or median would be your value you quote and the resulting uncertainty is the 16th and 84th percentile. To get a proper lower and upper error you would need to do the following; lower_err = median - 16th percentile, upper_err = 84th percentile - median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l16, med, u84 = np.percentile(flat_samples, q = (16, 50, 84), axis=0)\n",
    "lerr = med - l16\n",
    "uerr = u84 - med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
